// ------
// GraphX
// ------

// install scala
sudo apt-get install scala
scala -version

// setup the project directory and touch the graphx scala file
mkdir -p scala-project/src/main/scala
touch scala-project/src/main/scala/graphx.scala

// download sbt
wget https://github.com/sbt/sbt/releases/download/v1.8.2/sbt-1.8.2.tgz
tar -xf sbt-1.8.2.tgz
rm sbt-1.8.2.tgz
vim ~/.bashrc
export PATH=$PATH:/home/user/sbt/bin
source ~/.bashrc

// add build.sbt and package the jar
cd scala-project
vim build.sbt
  libraryDependencies ++= Seq(
    "org.apache.spark" %% "spark-core" % "3.3.1",
    "org.apache.spark" %% "spark-graphx" % "3.3.1"
  )
sbt package

// submit the job
spark-submit --class <class-name> <jar-path>

// dataset
wget https://snap.stanford.edu/data/web-Google.txt.gz
gzip -d web-Google.txt.gz
hdfs dfs -put web-Google.txt data/

// ------------------------------------------------------------------------------------------------

// -----
// Flink
// -----

// install flink
wget --no-check-certificate https://dlcdn.apache.org/flink/flink-1.16.1/flink-1.16.1-bin-scala_2.12.tgz
tar -xvf flink-1.16.1-bin-scala_2.12.tgz
mv flink-1.16.1 flink
vim ~/.bashrc
  export PATH=$PATH:/home/user/flink/bin
source ~/.bashrc
rm flink-1.16.1-bin-scala_2.12.tgz

// configure flink
vim flink/conf/masters > master
vim flink/conf/workers > master slave1 slave2
vim flink/conf/flink-conf.yaml
  jobmanager.rpc.address: <public-ipv4>
  jobmanager.bind-host: 0.0.0.0
  taskmanager.numberOfTaskSlots: 2
  parallelism.default: 6
  rest.address: <public-ipv4>
  rest.bind-address: 0.0.0.0

// quickstart
cd flink
cp opt/flink-gelly-1.16.1.jar lib/

cd ..
scp -r flink slave1:~
scp -r flink slave2:~
  vim ~/.bashrc
    export PATH=$PATH:/home/user/flink/bin
  source ~/.bashrc

start-cluster.sh
flink ui is available on <public-ipv4>:8081

sudo apt install maven -y
mvn archetype:generate                \
  -DarchetypeGroupId=org.apache.flink   \
  -DarchetypeArtifactId=flink-quickstart-java \
  -DarchetypeVersion=1.16.0

  adis
  triangleEnumerator
  1.0
  jar

add gelly dependency on pom.xml

  <dependency>
      <groupId>org.apache.flink</groupId>
      <artifactId>flink-gelly</artifactId>
      <version>1.16.0</version>
  </dependency>

change name on pom.xml
change mainClass on pom.xml
rename java file 
change java class name

mvn clean package
flink run target/<jar-name>.jar

stop-all.sh

vim ~/.bashrc
  export HADOOP_CLASSPATH=`hadoop classpath`
source ~/.bashrc

add dependencies to pom.xml

  <dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-hadoop-compatibility_2.12</artifactId>
			<version>1.16.0</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-client</artifactId>
			<version>3.3.4</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>3.3.4</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-hdfs</artifactId>
			<version>3.3.4</version>
			<scope>provided</scope>
		</dependency>

!!! USE HDFS INSTEAD OF LOCAL FILE !!!
!!! PARALLELISM AND MEMORY CONFIG!!!